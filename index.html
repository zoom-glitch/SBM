<!DOCTYPE html>
<html lang="ar">
<head>
  <meta charset="UTF-8" />
  <title>Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ù…ÙƒÙÙˆÙÙŠÙ† Ø§Ù„Ø°ÙƒÙŠ (Ø§Ø¶ØºØ· ÙˆØªØ­Ø¯Ø«)</title>
  <style>
    * { margin: 0; padding: 0; box-sizing: border-box; }
    html, body {
      width: 100%;
      height: 100%;
      background: black;
      font-family: 'Arial', sans-serif;
      overflow: hidden;
    }
    video {
      position: fixed;
      top: 0; left: 0;
      width: 100vw;
      height: 100vh;
      object-fit: cover;
      z-index: 0;
      background: black;
    }
    #objects {
      position: fixed;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      background: rgba(0, 0, 0, 0.8); /* Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ÙˆØ¶ÙˆØ­ */
      color: white;
      padding: 30px 40px;
      border-radius: 20px;
      font-size: 42px; /* ØªØµØºÙŠØ± Ø·ÙÙŠÙ Ù„ÙŠÙ„Ø§Ø¦Ù… Ø§Ù„Ø´Ø§Ø´Ø§Øª Ø§Ù„ØµØºÙŠØ±Ø© */
      font-weight: bold;
      text-align: center;
      max-width: 90%;
      line-height: 1.5;
      z-index: 10;
      cursor: pointer; /* Ù„Ø¥Ø¸Ù‡Ø§Ø± Ø£Ù† Ø§Ù„Ø¹Ù†ØµØ± Ù‚Ø§Ø¨Ù„ Ù„Ù„Ù†Ù‚Ø± */
      transition: background-color 0.3s;
    }
    #objects.listening {
        background-color: rgba(0, 80, 150, 0.9); /* ØªØºÙŠÙŠØ± Ø§Ù„Ù„ÙˆÙ† Ø¹Ù†Ø¯ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹ */
    }
  </style>
</head>
<body>
  <video id="video" autoplay muted playsinline></video>
  <div id="objects">ğŸ“¦ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚...</div>

  <!-- Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.14.0"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
  <script src="https://cdn.jsdelivr.net/npm/tesseract.js@2.1.5/dist/tesseract.min.js"></script>

  <script>
    const video = document.getElementById("video");
    const objectDiv = document.getElementById("objects");
    let model;
    let isProcessing = false; // Ù„Ù…Ù†Ø¹ Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ù…ØªØ¯Ø§Ø®Ù„Ø©

    // --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØª (Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©) ---
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    let recognition;

    if (SpeechRecognition) {
        recognition = new SpeechRecognition();
        recognition.lang = 'ar-EG';
        recognition.continuous = false; // *** Ø§Ù„ØªØºÙŠÙŠØ± Ø§Ù„Ø£Ù‡Ù…: Ù„Ø§ ØªØ³ØªÙ…Ø± ÙÙŠ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹ ***
        recognition.interimResults = false;
    } else {
        objectDiv.innerText = "âŒ Ø§Ù„Ù…ØªØµÙØ­ Ù„Ø§ ÙŠØ¯Ø¹Ù… Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØµÙˆØªÙŠØ©";
    }

    async function startCamera() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" }, audio: false });
        video.srcObject = stream;
      } catch (e) {
        objectDiv.innerText = "âŒ ÙØ´Ù„ ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§";
        console.error("Camera error:", e);
      }
    }

    async function loadModel() {
      try {
        objectDiv.innerText = "ğŸ“¦ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬...";
        model = await cocoSsd.load();
        objectDiv.innerText = "âœ… Ø¬Ø§Ù‡Ø²!\nØ§Ù†Ù‚Ø± Ø¹Ù„Ù‰ Ø§Ù„Ø´Ø§Ø´Ø© Ø«Ù… ØªØ­Ø¯Ø«.";
        speak("Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¬Ø§Ù‡Ø². Ø§Ù†Ù‚Ø± Ø¹Ù„Ù‰ Ø§Ù„Ø´Ø§Ø´Ø© Ù„Ø¥Ø¹Ø·Ø§Ø¡ Ø£Ù…Ø± ØµÙˆØªÙŠ.");
      } catch (e) {
        objectDiv.innerText = "âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬";
        console.error("Model load error:", e);
      }
    }

    function getArabicVoice() {
      const voices = speechSynthesis.getVoices();
      return voices.find(v => v.lang.includes("ar")) || null;
    }

    function speak(text) {
      if (!text || text.trim() === "") return;
      const msg = new SpeechSynthesisUtterance(text);
      msg.lang = 'ar-EG';
      msg.voice = getArabicVoice();
      msg.rate = 0.9;
      speechSynthesis.cancel();
      speechSynthesis.speak(msg);
    }
    
    // --- Ø¯Ø§Ù„Ø© Ù„ØªØ´ØºÙŠÙ„ ØµÙˆØª ØªÙ†Ø¨ÙŠÙ‡ ---
    function playBeep(start = true) {
        const audioContext = new (window.AudioContext || window.webkitAudioContext)();
        const oscillator = audioContext.createOscillator();
        oscillator.type = 'sine';
        oscillator.frequency.setValueAtTime(start ? 880 : 660, audioContext.currentTime); // ØªØ±Ø¯Ø¯ Ù…Ø®ØªÙ„Ù Ù„Ù„Ø¨Ø¯Ø§ÙŠØ© ÙˆØ§Ù„Ù†Ù‡Ø§ÙŠØ©
        oscillator.connect(audioContext.destination);
        oscillator.start();
        oscillator.stop(audioContext.currentTime + 0.1);
    }

    // --- Ø§Ù„Ø¯Ø§Ù„Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ± ---
    async function runObjectDetection() {
        objectDiv.innerText = "ğŸ¤” Ø£ÙÙƒØ±... Ù…Ø§ Ø§Ù„Ø°ÙŠ Ø£Ø±Ø§Ù‡ØŸ";
        const predictions = await model.detect(video);
        const labels = [...new Set(predictions.map(p => p.class))];
        if (labels.length === 0) return "Ù„Ø§ Ø£Ø±Ù‰ Ø´ÙŠØ¦Ù‹Ø§ ÙˆØ§Ø¶Ø­Ù‹Ø§.";
        const translatedLabels = await Promise.all(labels.map(async (text) => {
            try {
                const res = await fetch(`https://api.mymemory.translated.net/get?q=${text}&langpair=en|ar`);
                const data = await res.json();
                return data.responseData.translatedText || text;
            } catch { return text; }
        }));
        const joinWithWa = (list) => list.length === 1 ? list[0] : list.slice(0, -1).join("ØŒ ") + " Ùˆ" + list[list.length - 1];
        return "Ø£Ø±Ù‰ Ø£Ù…Ø§Ù…Ùƒ " + joinWithWa(translatedLabels);
    }

    async function runTextRecognition() {
        objectDiv.innerText = "ğŸ“– Ø¬Ø§Ø±ÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù†Øµ...";
        const { data: { text } } = await Tesseract.recognize(video, 'eng+ara');
        const cleanText = text.trim().split("\n").filter(t => t.length > 2).join(" ");
        return cleanText ? "Ø§Ù„Ù†Øµ Ø§Ù„Ù…ÙƒØªÙˆØ¨ Ù‡Ùˆ: " + cleanText : "Ù„Ù… Ø£Ø¬Ø¯ Ø£ÙŠ Ù†Øµ Ù„Ø£Ù‚Ø±Ø£Ù‡.";
    }

    // --- Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØµÙˆØªÙŠØ© Ø§Ù„Ø¬Ø¯ÙŠØ¯ ---
    if (recognition) {
        recognition.onresult = async (event) => {
            const command = event.results[0][0].transcript.trim().toLowerCase();
            console.log('ØªÙ… Ø³Ù…Ø§Ø¹ Ø§Ù„Ø£Ù…Ø±:', command);
            objectDiv.classList.remove('listening');
            playBeep(false); // ØµÙˆØª Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹

            let resultMessage = "";
            try {
                 if (command.includes("Ù…Ø§ Ø§Ù„Ø°ÙŠ Ø£Ù…Ø§Ù…ÙŠ") || command.includes("Ù…Ø§Ø°Ø§ Ø§Ù…Ø§Ù…ÙŠ") || command.includes("Ø´Ø§ÙŠÙ Ø§ÙŠÙ‡")) {
                    resultMessage = await runObjectDetection();
                } else if (command.includes("Ø§Ù‚Ø±Ø£") || command.includes("Ø§Ù‚Ø±Ø§") || command.includes("Ù…ÙƒØªÙˆØ¨")) {
                    resultMessage = await runTextRecognition();
                } else {
                    resultMessage = "Ù„Ù… Ø£ÙÙ‡Ù… Ø§Ù„Ø£Ù…Ø±. Ø­Ø§ÙˆÙ„ Ù‚ÙˆÙ„ 'Ù…Ø§ Ø§Ù„Ø°ÙŠ Ø£Ù…Ø§Ù…ÙŠ' Ø£Ùˆ 'Ø§Ù‚Ø±Ø£ Ø§Ù„Ù†Øµ'.";
                }
            } catch(err) {
                console.error("Processing error:", err);
                resultMessage = "Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªÙ†ÙÙŠØ° Ø·Ù„Ø¨Ùƒ.";
            }

            objectDiv.innerText = resultMessage;
            speak(resultMessage);
            isProcessing = false; // Ø§Ù„Ø³Ù…Ø§Ø­ Ø¨Ø£Ù…Ø± Ø¬Ø¯ÙŠØ¯
        };

        recognition.onerror = (event) => {
            console.error("Speech recognition error", event.error);
            objectDiv.innerText = "Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø§ÙŠÙƒØ±ÙˆÙÙˆÙ†. Ø§Ù†Ù‚Ø± Ù„Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø¬Ø¯Ø¯Ø§Ù‹.";
            objectDiv.classList.remove('listening');
            isProcessing = false;
        };
        
        recognition.onend = () => {
            // Ù„Ø§ ØªÙØ¹Ù„ Ø´ÙŠØ¦Ø§Ù‹ Ù‡Ù†Ø§ØŒ Ù„Ù† Ù†Ø¹ÙŠØ¯ Ø§Ù„ØªØ´ØºÙŠÙ„ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
            console.log("Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹ Ø§Ù†ØªÙ‡Ù‰.");
            if (!isProcessing) {
              objectDiv.classList.remove('listening');
            }
        };
    }

    // --- Ø¯Ø§Ù„Ø© Ø¬Ø¯ÙŠØ¯Ø© Ù„Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹ Ø¹Ù†Ø¯ Ø§Ù„Ø·Ù„Ø¨ ---
    function listenForCommand() {
        if (isProcessing || !recognition) return;
        
        isProcessing = true;
        playBeep(true); // ØµÙˆØª Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹
        objectDiv.innerText = "ğŸ¤ Ø§Ø³ØªÙ…Ø¹ Ø§Ù„Ø¢Ù†...";
        objectDiv.classList.add('listening');
        
        try {
            recognition.start();
        } catch (e) {
            console.error("Error starting recognition:", e);
            objectDiv.innerText = "Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹ Ø§Ù„Ø¢Ù†. Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.";
            isProcessing = false;
            objectDiv.classList.remove('listening');
        }
    }

    async function init() {
      await startCamera();
      await loadModel();
      // Ø§Ø³ØªØ¨Ø¯Ø§Ù„ ÙƒÙ„ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ø¨Ù†Ù‚Ø±Ø© ÙˆØ§Ø­Ø¯Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø´Ø§Ø´Ø© ÙƒÙ„Ù‡Ø§
      document.body.addEventListener("click", listenForCommand);
    }
    
    // Ù„Ø¶Ù…Ø§Ù† ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£ØµÙˆØ§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
    window.addEventListener("load", () => {
        setTimeout(() => speechSynthesis.getVoices(), 200);
    });

    init();
  </script>
</body>
</html>
