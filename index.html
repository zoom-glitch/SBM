<!DOCTYPE html>
<html lang="ar">
<head>
  <meta charset="UTF-8" />
  <title>Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ù…ÙƒÙÙˆÙÙŠÙ† Ø¨Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØµÙˆØªÙŠØ©</title>
  <style>
    * { margin: 0; padding: 0; box-sizing: border-box; }
    html, body {
      width: 100%;
      height: 100%;
      background: black;
      font-family: 'Arial', sans-serif;
      overflow: hidden;
    }
    video {
      position: fixed;
      top: 0; left: 0;
      width: 100vw;
      height: 100vh;
      object-fit: cover;
      z-index: 0;
    }
    #objects {
      position: fixed;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      background: rgba(0, 0, 0, 0.7);
      color: white;
      padding: 30px 40px;
      border-radius: 20px;
      font-size: 42px;
      font-weight: bold;
      text-align: center;
      max-width: 90%;
      line-height: 1.5;
      z-index: 10;
    }
  </style>
</head>
<body>
  <video id="video" autoplay muted playsinline></video>
  <div id="objects">ğŸ¤ Ù‚Ù„: "Ø§ÙŠÙ‡ Ø§Ù„Ù„ÙŠ Ù‚Ø¯Ø§Ù…ÙŠ" Ø£Ùˆ "Ø§Ù‚Ø±Ø§ Ø§Ù„ÙƒØªØ§Ø¨"</div>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.14.0"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
  <script src="https://cdn.jsdelivr.net/npm/tesseract.js@2.1.5/dist/tesseract.min.js"></script>

  <script>
    const video = document.getElementById("video");
    const objectDiv = document.getElementById("objects");
    let model, lastResult = "";

    async function startCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" } });
      video.srcObject = stream;
    }

    async function loadModel() {
      model = await cocoSsd.load();
    }

    function getArabicVoice() {
      const voices = speechSynthesis.getVoices();
      return voices.find(v => v.lang.includes("ar") && v.name.includes("Google")) ||
             voices.find(v => v.lang.includes("ar")) || null;
    }

    function speak(text) {
      const msg = new SpeechSynthesisUtterance(text);
      msg.lang = 'ar-EG';
      msg.voice = getArabicVoice();
      msg.rate = 0.9;
      speechSynthesis.cancel();
      speechSynthesis.speak(msg);
    }

    async function describeScene() {
      const predictions = await model.detect(video);
      const labels = [...new Set(predictions.map(p => p.class))];
      let sentence = labels.length ? "Ù‚Ø¯Ø§Ù…Ùƒ " + labels.join(" Ùˆ") : "Ù…Ø´ Ø´Ø§ÙŠÙ Ø­Ø§Ø¬Ø© ÙˆØ§Ø¶Ø­Ø©";
      objectDiv.innerText = sentence;
      speak(sentence);
      lastResult = sentence;
    }

    async function readText() {
      const canvas = document.createElement("canvas");
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      const ctx = canvas.getContext("2d");
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      const { data: { text } } = await Tesseract.recognize(canvas, 'eng');
      const clean = text.trim().replace(/\\n/g, " ").substring(0, 300);
      const sentence = clean ? "Ù…ÙƒØªÙˆØ¨: " + clean : "Ù…Ø´ Ø´Ø§ÙŠÙ ÙƒØªØ§Ø¨Ø© ÙˆØ§Ø¶Ø­Ø©";
      objectDiv.innerText = sentence;
      speak(sentence);
      lastResult = sentence;
    }

    function listenToUser() {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      const recognition = new SpeechRecognition();
      recognition.lang = 'ar-EG';
      recognition.continuous = true;
      recognition.interimResults = false;

      recognition.onresult = e => {
        const command = e.results[e.results.length - 1][0].transcript.trim();
        if (command.includes("Ø§ÙŠÙ‡") || command.includes("Ù‚Ø¯Ø§Ù…ÙŠ")) describeScene();
        else if (command.includes("Ø§Ù‚Ø±Ø§") || command.includes("Ù‚Ø±Ø§Ø¡Ø©")) readText();
        else if (command.includes("Ø§Ø³ÙƒØª")) speechSynthesis.cancel();
        else if (command.includes("ÙƒØ±Ø±") || command.includes("Ø¹ÙŠØ¯")) speak(lastResult);
      };

      recognition.onerror = e => console.error("Voice error:", e);
      recognition.start();
    }

    async function init() {
      await startCamera();
      await loadModel();
      speak("Ø£Ù†Ø§ Ø¬Ø§Ù‡Ø²ØŒ Ù‚Ù„ Ø§ÙŠÙ‡ Ø§Ù„Ù„ÙŠ Ù‚Ø¯Ø§Ù…ÙŠ Ø£Ùˆ Ø§Ù‚Ø±Ø§ Ø§Ù„ÙƒØªØ§Ø¨");
      listenToUser();
    }

    window.addEventListener("click", () => speechSynthesis.getVoices());
    init();
  </script>
</body>
</html>
